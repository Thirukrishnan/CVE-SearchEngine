import os
import re
import gzip
import json
import argparse
import requests
from tqdm import tqdm

short = None


CVEs = list()


class bcolors:
    """
   
    """
    c = {
        'BLUE': '\033[94m',
        'LOW': '\033[92m',
        'MEDIUM': '\033[93m',
        'HIGH': '\033[91m',
        'CRITICAL': '\033[95m',
        'ENDC': '\033[0m',
        'BOLD': '\033[1m',
        'UNDERLINE': '\033[4m'
    }

    def h(s):
        return f"{bcolors.c['BOLD']}{s}:{bcolors.c['ENDC']}"

    def cseverity(s):
        if s in bcolors.c:
            return bcolors.c[s]
        bcolors.c['BOLD']


def shorten():
    """
    shorten() will output a simple description of the CVEs found
    instead of the default JSON formatted output.
    """
    i = len(CVEs)

    if i == 0:
        print("No CVEs found")
        return

    for entry in CVEs:
        print(f'''
{bcolors.h('ID')} {
    bcolors.c['UNDERLINE']}{entry['cve']['CVE_data_meta']['ID']}{
        bcolors.c['ENDC']}
{bcolors.h('DATE')} {entry['publishedDate']}
{bcolors.h('IMPACT')}''')
        if 'baseMetricV3' in entry['impact']:
            severity = \
                    entry['impact']['baseMetricV3']['cvssV3']['baseSeverity']
            print(f'''    Base Score: {bcolors.cseverity(severity)}{
        entry['impact']['baseMetricV3']['cvssV3']['baseScore']}{
            bcolors.c['ENDC']}
    Severity: {bcolors.cseverity(severity)}{severity}{bcolors.c['ENDC']}
    Vector: {entry['impact']['baseMetricV3']['cvssV3']['vectorString']}''')
        else:
            print('''    Undefined.''')
        print(f'''
{bcolors.h('DESC')} {entry['cve']['description']['description_data'][0]['value']}''')
        i -= 1
        if i > 0:
            print("---")


def search(count,data_json: object, search_query: str, in_decription: bool = False):
    """
    This function parses the NIST JSON data,
    identifies each CVE, and searches for the
    given query on each of the CVE description.
    """
    # The user can specify the maximum results to retrieve
    # This is stored in the global variable: count
    max_results_counter = 0

    # Create the regex to search for the query on the data
    regex = re.compile(f'({search_query})', re.I)

    for entry in data_json['CVE_Items']:
        # Filter for CVE entries
        # use CPE entries
        # If the maximum results are reached, exit
        if max_results_counter == count:
            break
        if ('configurations' in entry and
                len(entry['configurations']['nodes']) > 0):
            found = False
            for node in entry['configurations']['nodes']:
                for cpe in node['cpe_match']:
                    if regex.search(cpe['cpe23Uri']) is not None:
                        CVEs.append(entry)
                        max_results_counter += 1
                        found = True
                        break
            if found:
                # if item found already using CPE entry then continue
                continue

        # use the description as search data
        if 'cve' in entry and in_decription:
            # Obtain CVE description
            cve_description = entry['cve']['description']
            # Process each description data?
            for d in cve_description['description_data']:
                # Find the first match of search query regex
                # in the CVE description data retrieved
                if regex.search(d['value']) is not None:
                    CVEs.append(entry)
                    max_results_counter += 1
                    break
       

    if short:
        shorten()


def download_nist_data(year: int) -> object:
    """
    Donwload NIST CVE data for a given year
    """
    try:
       
        data_path = f"{os.getcwd()}/data"
        data_file = f"{data_path}/nvdcve-1.1-{year}.json.gz"
        url = f"https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-{str(year)}.json.gz"
                # Should be one global variable
        content = requests.get(url, stream=True, headers={"Accept-Encoding": "gzip"})
        total_size_in_bytes= int(content.headers.get('content-length', 0))
        block_size = 1024 #1 Kibibyte
        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)
        with open(data_file, 'wb') as file:
            for data in content.iter_content(block_size):
                progress_bar.update(len(data))
                file.write(data)
        progress_bar.close()
        if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:
            print("ERROR, something went wrong")
        # Download NIST data for a given year
        content = requests.get(url, headers={"Accept-Encoding": "gzip"})

        # If download was not successful raise exception
        if content.status_code != 200:
            raise Exception("Error requesting compressed NIST JSON.")

        # If download was successful
        # First, save it locally
        open(data_file, 'wb').write(content.content)

        # Second, load it as JSON
        try:
            data = json.loads(gzip.decompress(content.content))
        except json.decoder.JSONDecodeError as err:
            raise Exception(f"Error decoding NIST JSON: {err}")

        return data

    except Exception as err:
        print(f"Exception in download_nist_data: {err}")
        return None


def retrieve_nist_data_from_cache(year: int) -> object:
    """
    Check local cache if NIST data for a given
    year already exists. If yes, use it.
    """
    try:
        data_file = "nvdcve-1.1-{YEAR}.json.gz"
        data_path = f"{os.getcwd()}/data"

        # NIST file for the year we are searching
        nist_file = f"{data_path}/{data_file.replace('{YEAR}', str(year))}"

        # Check if file exists in path
        if os.path.exists(nist_file) and os.path.getsize(nist_file) > 30000:
            with gzip.open(nist_file, 'rb') as nist_data:
                try:
                    return json.loads(nist_data.read())
                except json.decoder.JSONDecodeError as err:
                    raise Exception(f"Error decoding NIST JSON: {err}")

        # In any other case, return false
        return None
    except Exception as err:
        print(f"Exception in retrieve_nist_data_from_cache: {err}")


def main(year, search_query, count):
    global args, short
    short=True
    search_years = None

    year_min, year_max = year         
    search_years = range(int(year_min), int(year_max)+1)

    # Search for CVE for every year
    for year in search_years:
        # Attempting to retrieve data from local cache
        nist_data = retrieve_nist_data_from_cache(year)
        if not nist_data:
            # If no local cache found, download NIST data for a given year
            nist_data = download_nist_data(year)
        search_description=True
        # Search in the downloaded data
        if nist_data:
            search(count,nist_data, search_query)
        else:
            print("Error retrieving NIST data {nist_data}")

    return CVEs
if __name__ == '__main__':
     main((2020,2021),"apache",3)
